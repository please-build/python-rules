""" Rules to build Python code.

The output artifacts for Python rules are .pex files (see https://github.com/pantsbuild/pex).
Pex is a rather nice system for combining Python code and all needed dependencies
(excluding the actual interpreter and possibly some system level bits) into a single file.

The process of compiling pex files can be a little slow when including many large files, as
often happens when one's binary includes large compiled dependencies (eg. numpy...). Hence
we have a fairly elaborate optimisation whereby each python_library rule builds a little
zipfile containing just its sources, and all of those are combined at the end to produce
the final .pex. This builds at roughly the same pace for a clean build of a single target,
but is drastically faster for building many targets with similar dependencies or rebuilding
a target which has only had small changes.
"""


def python_library(name:str, srcs:list=[], resources:list=[], deps:list=[], visibility:list=None,
                   test_only:bool&testonly=False, zip_safe:bool=True, labels:list&features&tags=[], interpreter:str=None,
                   strip:bool=False):
    """Generates a Python library target, which collects Python files for use by dependent rules.

    Note that each python_library performs some pre-zipping of its inputs before they're combined
    in a python_binary or python_test. Hence while it's of course not required that all dependencies
    of those rules are python_library rules, it's often a good idea to wrap any large dependencies
    in one to improve incrementality (not necessary for pip_library, of course).

    Args:
      name (str): Name of the rule.
      srcs (list): Python source files for this rule.
      resources (list): Non-Python files that this rule collects which will be included in the final .pex.
                        The distinction between this and srcs is fairly arbitrary and historical, but
                        semantically quite nice and parallels python_test.
      deps (list): Dependencies of this rule.
      visibility (list): Visibility specification.
      test_only (bool): If True, can only be depended on by tests.
      zip_safe (bool): Should be set to False if this library can't be safely run inside a .pex
                       (the most obvious reason not is when it contains .so modules).
                       See python_binary for more information.
      labels (list): Labels to apply to this rule.
      interpreter (str): The Python interpreter to use. Defaults to the config setting
                         which is normally just 'python', but could be 'python3' or
                         'pypy' or whatever.
      strip (bool): If True, the original sources are stripped and only bytecode is output.
      labels (list): Any labels to apply to this rule.
    """
    if not zip_safe:
        labels += ['py:zip-unsafe']
    if srcs or resources:
        cmd = f'$TOOLS_JARCAT z -d -o ${OUTS} -i .'

        # For some reason jarcat isn't unflattening .whl files so do it manually here till I figure out why
        unzip_cmd = f'for i in $(find . -name \'*.whl\'); do mv $i .; unzip $(basename "$i"); done'

        interpreter = interpreter or CONFIG.PYTHON.DEFAULT_INTERPRETER
        if srcs:
            # This is a bit of a hack, but rather annoying. We want to put bytecode in its 'legacy' location
            # in python3 because zipimport doesn't look in __pycache__. Unfortunately the flag doesn't exist
            # in python2 so we have to guess whether we should apply it or not.
            bytecode_flag = '-b' if 'python3' in interpreter or 'pypy3' in interpreter else ''
            compile_cmd = f'$TOOLS_INT -S -m compileall {bytecode_flag} -f $SRCS_SRCS'
            if strip:
                cmd = ' && '.join([unzip_cmd, compile_cmd, 'rm -f $SRCS_SRCS', cmd])
            else:
                cmd = ' && '.join([unzip_cmd, compile_cmd, cmd])

        # Pre-zip the files for later collection by python_binary.
        zip_rule = build_rule(
            name=name,
            tag='zip',
            srcs={
                'SRCS': srcs,
                'RES': resources,
            },
            outs=[f'.{name}.pex.zip'],
            cmd=cmd,
            building_description='Compressing...',
            requires=['py'],
            test_only=test_only,
            output_is_complete=True,
            tools={
                'int': [interpreter],
                'jarcat': [CONFIG.JARCAT_TOOL],
            },
            labels = labels,
        )
        deps += [zip_rule]
    elif strip:
        fail("Can't pass strip=True to a python_library with no srcs")

    return filegroup(
        name=name,
        srcs=resources if strip else (srcs + resources),
        deps=deps,
        visibility=visibility,
        output_is_complete=False,
        requires=['py'],
        test_only=test_only,
        labels=labels,
    )


def python_binary(name:str, main:str, srcs:list=[], resources:list=[], out:str=None, deps:list=[],
                  data:list=None, visibility:list=None, test_only:bool=False, zip_safe:bool=None,
                  site:bool=False, strip:bool=False,
                  interpreter:str=None, shebang:str='', labels:list&features&tags=[]):
    """Generates a Python binary target.

    This compiles all source files together into a single .pex file which can
    be easily copied or deployed. The construction of the .pex is done in parts
    by the dependent python_library rules, and this rule simply builds the
    metadata for it and concatenates them all together.

    Args:
      name (str): Name of the rule.
      main (str): Python file which is the entry point and __main__ module.
      srcs (list): List of additional Python source files for this binary.
      resources (list): List of static resources to include in the .pex.
      data (list): Runtime data files for this rule.
      out (str): Name of the output file. Default to name + .pex
      deps (list): Dependencies of this rule.
      visibility (list): Visibility specification.
      test_only (bool): If True, can only be depended on by tests.
      zip_safe (bool): Allows overriding whether the output is marked zip safe or not.
                       If set to explicitly True or False, the output will be marked
                       appropriately; by default it will be safe unless any of the
                       transitive dependencies are themselves marked as not zip-safe.
      strip (bool): Strips source code from the output .pex file, leaving just bytecode.
      site (bool): Allows the Python interpreter to import site; conversely if False, it will be
                   started with the -S flag to avoid importing site.
      interpreter (str): The Python interpreter to use. Defaults to the config setting
                         which is normally just 'python', but could be 'python3' or
                         'pypy' or whatever.
      shebang (str): Exact shebang to apply to the generated file. By default we will
                     determine something appropriate for the given interpreter.
      labels (list): Labels to apply to this rule.
    """
    interpreter = interpreter or CONFIG.PYTHON.DEFAULT_INTERPRETER
    shebang = shebang or _set_shebang(interpreter, CONFIG.PYTHON.INTERPRETER_OPTIONS, site)
    zipsafe_flag = '' if zip_safe is False else '--zip_safe'
    cmd = '$TOOLS_PEX -s "%s" -m "%s" %s --interpreter_options="%s" --stamp="$RULE_HASH"' % (
        shebang, CONFIG.PYTHON_MODULE_DIR, zipsafe_flag, CONFIG.PYTHON.INTERPRETER_OPTIONS)
    if site:
        cmd += ' -S'

    cmd += f'; mv __main__.py {name}_main.py'

    assert main not in srcs, "main file should not be included in srcs"

    lib_rule = python_library(
        name='_%s#lib' % name,
        srcs=[main] + srcs,
        resources=resources,
        interpreter=interpreter,
        deps=deps,
        visibility=visibility,
        test_only=test_only,
    )

    # Use the pex tool to compress the entry point & add all the bootstrap helpers etc.
    pex_rule = build_rule(
        name = name,
        tag = 'pex',
        srcs=[main],
        outs=[f'{name}_main.py'],
        cmd=cmd,
        requires=['py', 'pex'],
        pre_build=_handle_zip_safe if zip_safe is None else None,
        deps=deps,
        needs_transitive_deps=True,  # Needed so we can find anything with zip_safe=False on it.
        output_is_complete=True,
        tools={
            'interpreter': [interpreter],
            'pex': [CONFIG.PYTHON.PEX_TOOL],
        },
        test_only=test_only,
    )

    # This rule concatenates the .pex with all the other precompiled zip files from dependent rules.
    cmd = f'mv $SRC __main__.py && $TOOL z -i . -s .pex.zip -s .whl --preamble="{shebang}" --include_other --add_init_py --strict'
    if strip:
        cmd += ' --strip_py'

    return build_rule(
        name=name,
        srcs=[pex_rule],
        deps=[lib_rule],
        outs=[out or (name + '.pex')],
        data=data,
        cmd=cmd,
        needs_transitive_deps=True,
        binary=True,
        output_is_complete=True,
        building_description="Creating pex...",
        visibility=visibility,
        requires=['py', interpreter or CONFIG.PYTHON.DEFAULT_INTERPRETER],
        tools=[CONFIG.JARCAT_TOOL],
        # This makes the python_library rule the dependency for other python_library or
        # python_test rules that try to import it. Does mean that they cannot collect a .pex
        # by depending directly on the rule, they'll just get the Python files instead.
        # This is not a common case anyway; more usually you'd treat that as a runtime data
        # file rather than trying to pack into a pex. Can be worked around with an
        # intermediary filegroup rule if really needed.
        provides={'py': lib_rule},
        labels=labels,
        test_only=test_only,
    )


def _set_shebang(interpreter:str, interpreter_options:str, site:bool):
    # Assume the path to the interpreter is relative
    # Do we need to trim space here?
    shebang = f'/usr/bin/env {interpreter}'
    if not site:
        if ' ' in shebang:
            shebang = f'#!/bin/sh\nexec {shebang} -S \\\\$0 \\\"\\\\$@\\\"'
        else:
            shebang += ' -S'
    if not shebang.startswith('#!'):
        shebang = '#!' + shebang

    return shebang + '\n'


def python_test(name:str, srcs:list, data:list|dict=[], resources:list=[], deps:list=[], worker:str='',
                labels:list&features&tags=[], size:str=None, flags:str='', visibility:list=None,
                sandbox:bool=None, timeout:int=0, flaky:bool|int=0,
                test_outputs:list=None, zip_safe:bool=None, interpreter:str=None, site:bool=False,
                test_runner:str=None):
    """Generates a Python test target.

    This works very similarly to python_binary; it is also a single .pex file
    which is run to execute the tests. The tests are run via either unittest or pytest, depending
    on which is set for the test runner, which can be configured either via the python_test_runner
    package property or python.testrunner in the config.

    Args:
      name (str): Name of the rule.
      srcs (list): Source files for this test.
      data (list): Runtime data files for the test.
      resources (list): Non-Python files to be included in the pex. Note that the distinction
                        vs. srcs is important here; srcs are passed to unittest for it to run
                        and it may or may not be happy if given non-Python files.
      deps (list): Dependencies of this rule.
      worker (str): Reference to worker script, A persistent worker process that is used to set up the test.
      labels (list): Labels for this rule.
      size (str): Test size (enormous, large, medium or small).
      flags (str): Flags to apply to the test command.
      visibility (list): Visibility specification.
      sandbox (bool): Sandbox the test on Linux to restrict access to namespaces such as network.
      timeout (int): Maximum time this test is allowed to run for, in seconds.
      flaky (int | bool): True to mark this test as flaky, or an integer for a number of reruns.
      test_outputs (list): Extra test output files to generate from this test.
      zip_safe (bool): Allows overriding whether the output is marked zip safe or not.
                       If set to explicitly True or False, the output will be marked
                       appropriately; by default it will be safe unless any of the
                       transitive dependencies are themselves marked as not zip-safe.
      interpreter (str): The Python interpreter to use. Defaults to the config setting
                         which is normally just 'python', but could be 'python3' or
                        'pypy' or whatever.
      site (bool): Allows the Python interpreter to import site; conversely if False, it will be
                   started with the -S flag to avoid importing site.
      test_runner (str): Specify which Python test runner to use for these tests. One of
                         `unittest`, `pytest`, or a custom test runner entry point.
    """
    interpreter = interpreter or CONFIG.PYTHON.DEFAULT_INTERPRETER
    test_runner = test_runner or CONFIG.PYTHON.TEST_RUNNER
    module_dir = CONFIG.PYTHON.MODULE_DIR
    interpreter_options = CONFIG.PYTHON.INTERPRETER_OPTIONS
    # TODO: Remove add_test_runner_deps flag from pex tool as the deps are now added here
    cmd = f'$TOOLS_PEX -t -s {interpreter} -m {module_dir} -r {test_runner} --zip_safe --interpreter_options={interpreter_options} --stamp="$RULE_HASH"'
    if site:
        cmd += ' -S'

    cmd += f'; mv __main__.py {name}_main.py'

    # Use the pex tool to template the entry point
    pex_rule = build_rule(
        name = name,
        tag = 'pex',
        srcs=srcs,
        outs=[f'{name}_main.py'],
        cmd=cmd,
        requires=['py'],
        test_only=True,
        needs_transitive_deps=True,  # needed for zip-safe detection
        building_description="Creating pex info...",
        pre_build=_handle_zip_safe,
        deps=deps,
        tools={
            'interpreter': [interpreter or CONFIG.PYTHON.DEFAULT_INTERPRETER],
            'pex': [CONFIG.PYTHON.PEX_TOOL],
        },
        labels = labels,
    )

    deps += [pex_rule]
    lib_rule = python_library(
        name=f'_%s#lib' % name,
        srcs=srcs,
        resources=resources,
        interpreter=interpreter,
        deps=deps,
        test_only=True,
        visibility=visibility,
        labels = labels,
    )

    deps = [pex_rule, lib_rule]
    shebang = _set_shebang(interpreter, interpreter_options, site)

    # If there are resources specified, they have to get built into the pex.
    # If the specified test-runner is one of unittest, pytest, or behave, we will add the
    # required deps here. Otherwise, we'll check if the config specifies a
    # PYTHON_TEST_RUNNER_BOOTSTRAP target and add that as a dependency.
    # bootstrap = CONFIG.PYTHON.TEST_RUNNER_BOOTSTRAP

    if test_runner == 'unittest':
        deps += ["@self//third_party/python:unittest_bootstrap"]
    elif test_runner == 'pytest':
        deps += ["@self//third_party/python:pytest_bootstrap"]
    elif test_runner == 'behave':
        deps += ["//third_party/python:behave"]
    elif bootstrap:
        deps += [bootstrap] if bootstrap not in deps else []


    test_cmd = f'$TEST {flags}'
    if worker:
        test_cmd = f'$(worker {worker}) && {test_cmd} '
        deps += [worker]

    # This rule concatenates the .pex with all the other precompiled zip files from dependent rules.
    return build_rule(
        name=name,
        srcs=[pex_rule],
        deps=deps,
        # N.B. the actual test sources are passed as data files as well. This is needed for pytest but
        #      is faster for unittest as well (because we don't need to rebuild the pex if they change).
        data=data | {'_srcs': srcs} if isinstance(data, dict) else data + srcs,
        outs=[f'{name}.pex'],
        labels=labels + ['test_results_dir'],
        cmd=f"mv $SRC __main__.py && for i in $(find . -name \'*.whl\'); do mv $i .; unzip $(basename \"$i\"); done && $TOOL z -i . -s .pex.zip --preamble=\"{shebang}\" --include_other --add_init_py --strict",
        test_cmd=test_cmd,
        needs_transitive_deps=True,
        output_is_complete=True,
        binary=True,
        test=True,
        test_sandbox=sandbox,
        building_description="Building pex...",
        visibility=visibility,
        test_timeout=timeout,
        size = size,
        flaky=flaky,
        test_outputs=test_outputs,
        requires=['py', 'test', interpreter or CONFIG.PYTHON.DEFAULT_INTERPRETER],
        tools=[CONFIG.JARCAT_TOOL],
    )

def python_wheel(name:str, version:str, hashes:list=None, package_name:str=None, outs:list=None,
                 post_install_commands:list=None, patch:str|list=None, licences:list=None,
                 test_only:bool&testonly=False, repo:str=None, zip_safe:bool=True, visibility:list=None,
                 deps:list=[], name_scheme:str=None, strip:list=['*.pyc', 'tests'],
                 tool:str=CONFIG.PYTHON.WHEEL_TOOL):
    """Downloads a Python wheel and extracts it.

    This is a lightweight pip-free alternative to pip_library which supports cross-compiling.
    Rather than leaning on pip which is difficult to achieve reproducible builds with and
    support on different platforms, this rule is a simple wrapper around curl and unzip.
    Unless otherwise specified, the wheels are expected to adhere to common naming schemes,
    such as:
      <package_name>-<version>[-<os>-<arch>].whl
      <package_name>-<version>[-<os>_<arch>].whl
      <package_name>-<version>.whl

    Args:
      name (str): Name of the rule. Also doubles as the name of the package if package_name
            is not set.
      version (str): Version of the package to install.
      hashes (list): List of hashes to verify the package against.
      package_name (str): If given, overrides `name` for the name of the package to look for.
      outs (list): List of output files. Defaults to a directory named the same as `name`.
      post_install_commands (list): Commands to run after 'install'.
      patch (str | list): Patch file to apply after install to fix any upstream code that has
                          done bad things.
      licences (list): Licences that this rule is subject to.
      test_only (bool): If True, this library can only be used by tests.
      repo (str): Repository to download wheels from.
      zip_safe (bool): Flag to indicate whether a pex including this rule will be zip-safe.
      visibility (list): Visibility declaration.
      deps (list): Dependencies of this rule.
      name_scheme (str): The templatized wheel naming scheme (available template variables
                         are `url_base`, `package_name`, `initial`, and `version`).
      strip (list): Files to strip after install. Note that these are done at any level.
      tool (str): Tool to locate python wheel file in an index
    """
    package_name = package_name or name.replace('-', '_')
    initial = package_name[0]
    url_base = repo or CONFIG.PYTHON.WHEEL_REPO
    urls = []
    if url_base:
        if name_scheme:
            urls += [name_scheme.format(url_base=url_base,
                                        package_name=package_name,
                                        initial=initial,
                                        version=version)]
        elif CONFIG.PYTHON.WHEEL_NAME_SCHEME:
            urls += [scheme.format(url_base=url_base, package_name=package_name, initial=initial, version=version)
                     for scheme in CONFIG.PYTHON.WHEEL_NAME_SCHEME]
        else:
            # Populate urls using a reasonable set of possible wheel naming schemes.
            # Look for an arch-specific wheel first; in some cases there can be both (e.g. protobuf
            # has optional arch-specific bits) and we prefer the one with the cool stuff.
            urls += ['{url_base}/{package_name}-{version}-${{OS}}-${{ARCH}}.whl'.format(url_base=url_base,
                                                                                        package_name=package_name,
                                                                                        initial=initial,
                                                                                        version=version),
                     '{url_base}/{package_name}-{version}-${{OS}}_${{ARCH}}.whl'.format(url_base=url_base,
                                                                                        package_name=package_name,
                                                                                        initial=initial,
                                                                                        version=version),
                     '{url_base}/{package_name}-{version}.whl'.format(url_base=url_base,
                                                                      package_name=package_name,
                                                                      initial=initial,
                                                                      version=version)]

    file_rule = None
    if tool:
        # Try the urls generated using the default wheel name schemes. If those fail, try
        # generating a url with the wheel_resolver tool and download that if successful.
        cmd = ['FOUND=false; DOWNLOAD=""']
        cmd += ['for URL in ' + ' '.join(urls)]
        cmd += ['do if wget -q --method=HEAD $URL']
        cmd += ['then FOUND=true; DOWNLOAD="$URL"']
        cmd += ['break; fi; done']

        cmd += ['if [ "$FOUND" = true ]']
        cmd += ['then wget -O "$OUTS" "$DOWNLOAD"']
        cmd += ['else $TOOL --package ' + package_name + ' --version ' + version + '; fi']

        file_rule = build_rule(
            name = name,
            tag = 'download',
            outs = [name + '.whl'],
            cmd = '; '.join(cmd),
            tools = [tool],
            hashes = hashes if CONFIG.FF_PYTHON_WHEEL_HASHING else None,
            licences = licences if licences else None,
            building_description = 'Extracting...',
        )

    elif urls:
        file_rule = remote_file(
            name = name,
            _tag = 'download',
            out = name + '.whl',
            url = urls,
            hashes = hashes if CONFIG.FF_PYTHON_WHEEL_HASHING else None,
            licences = licences if licences else None,
        )

    else:
        fail(f'No urls found for python_wheel rule {name}')

    cmd = ['$TOOL x $SRCS_SRC']

    if strip:
        cmd += ['find . %s | xargs rm -rf' % ' -or '.join(['-name "%s"' % s for s in strip])]
    if not licences:
        cmd += ['find . -name METADATA -or -name PKG-INFO | grep -v "^./build/" | '
                'xargs grep -E "License ?:" | grep -v UNKNOWN | cat || true']
    if patch:
        patches, c = _patch_cmd(patch)
        cmd += c
    if post_install_commands:
        cmd += post_install_commands

    cmd += ['$TOOL z -d --prefix $PKG -i ' + ' -i '.join(outs or [name])]
    label = f'whl:{package_name}=={version}'

    wheel_rule = build_rule(
        name = name,
        tag = 'wheel',
        cmd = ' && '.join(cmd),
        outs = [name + '.pex.zip'],
        srcs = {
            'src': [file_rule],
            'res': patches if patch else [],
        },
        building_description = 'Repackaging...',
        requires = ['py'],
        deps = deps,
        test_only = test_only,
        licences = licences,
        tools = [CONFIG.JARCAT_TOOL],
        post_build = None if licences else _add_licences,
        sandbox = False,
        labels = ['py:zip-unsafe', label] if not zip_safe else [label],
    )

    cmd = '$TOOL x $SRCS -s $PKG_DIR'
    if outs:
        # Hacky solution to handle things being in subdirectories in awkward ways.
        before, _, after = outs[0].partition('/')
        if after:
            cmd = f'rm -rf {before} && {cmd}'

    return build_rule(
        name = name,
        srcs = [wheel_rule],
        hashes = None if CONFIG.FF_PYTHON_WHEEL_HASHING else hashes,
        outs = outs or [name],
        tools = [CONFIG.JARCAT_TOOL],
        cmd = cmd,
        deps = deps,
        visibility = visibility,
        licences = licences,
        test_only = test_only,
        labels = [label],
        provides = {'py': wheel_rule},
    )

def _patch_cmd(patch):
    """Returns a command for the given patch or patches, with OS-specific tweaks where needed."""
    patches = [patch] if isinstance(patch, str) else patch
    if CONFIG.HOSTOS == 'freebsd':
        # --no-backup-if-mismatch is not supported, but we need to get rid of the .orig
        # files for hashes to match correctly.
        return patches, [f'patch -p0 < $(location {patch})' for patch in patches] + ['find . -name "*.orig" | xargs rm']
    else:
        return patches, [f'patch -p0 --no-backup-if-mismatch < $(location {patch})' for patch in patches]


def _handle_zip_safe(name):
    """Handles the zip safe flag.

    This works as a pre-build function and hence can only use the builtin
    methods to manipulate the rule.
    """
    if has_label(name, 'py:zip-unsafe'):
        set_command(name, get_command(name).replace(' --zip_safe', ''))

def _add_licences(name, output):
    """Annotates a python_wheel rule with detected licences after download."""
    found = False
    for line in output:
        if line.startswith('License: '):
            for licence in line[9:].split(' or '):  # Some are defined this way (eg. "PSF or ZPL")
                add_licence(name, licence)
                found = True
        elif line.startswith('Classifier: License'):
            # Oddly quite a few packages seem to have UNKNOWN for the licence but this Classifier
            # section still seems to know what they are licenced as.
            add_licence(name, line.split(' :: ')[-1])
            found = True
    if not found:
        log.warning('No licence found for %s, should add licences = [...] to the rule', name.lstrip('_').split('#')[0])

if CONFIG.BAZEL_COMPATIBILITY:
    py_library = python_library
    py_binary = python_binary
    py_test = python_test
